{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Lecture 7 - Optimization Problems using Theano\n",
    "\n",
    "#What you will learn in this session\n",
    "1.  How to use Theano to implement the gradient descent techniques that you've learned\n",
    "2.  How to use Theano to implement the simple ANN that you've seen.  \n",
    "\n",
    "#Order of Topics\n",
    "1.  Using Theano for function minimization\n",
    "2.  Using Theano to train a simple ANN\n",
    "\n",
    "#Using Theano for function minimization (and maximization).\n",
    "\n",
    "Now that you've got the basics of Theano and an understanding of gradient descent, you're ready to use Theano to do gradient descent.  The first problem will be a simple maximization of a real-valued function of several variables.  For an example, here's a function in the shape of a multidimensional Gaussian density.  \n",
    "\n",
    "$f(x) = e^{-\\frac12(x - m)^T(x - m)}$\n",
    "\n",
    "In this equation $x, m \\in\\mathbb{R^n}$.  x is the variable that you'll find by gradient descent.  m is like the mean value in a Gaussian density.  Notice that the argument of the exponential is always less than or equal to zero and that it's only equal to zero when $x = m$.  Therefore the point that maximizes f(x) is $x = m$.  The function f(x) has the shape of a Gaussian density but it's missing the multiplicative normalizing constant so that the area under f(x) is not equal to 1.  The code snip below shows Theano code for maximizing f(x) using gradient descent.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.00091188  0.00182376  0.00273565] 0.000923592617972\n",
      "10 [ 0.01067264  0.02134528  0.03201792] 0.00105799424176\n",
      "20 [ 0.02182399  0.04364798  0.06547197] 0.00123362517897\n",
      "30 [ 0.03479875  0.0695975   0.10439625] 0.00147176314327\n",
      "40 [ 0.05026133  0.10052265  0.15078398] 0.00181073064956\n",
      "50 [ 0.06930423  0.13860845  0.20791268] 0.00232656499668\n",
      "60 [ 0.09390395  0.1878079   0.28171185] 0.00319211890747\n",
      "70 [ 0.12818393  0.25636786  0.38455178] 0.00489058745742\n",
      "80 [ 0.1830675  0.366135   0.5492025] 0.00935680898265\n",
      "90 [ 0.30663705  0.6132741   0.91991116] 0.0345528499153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'exp((TensorConstant{-0.5} * Sum{acc_dtype=float64}(((x - TensorConstant{[ 1.  2.  3.]}) ** TensorConstant{2}))))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__author__ = 'mike.bowles'\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano import function\n",
    "import numpy as np\n",
    "\n",
    "x = theano.shared(np.array([0.0, 0.0, 0.0]), name='x')\n",
    "cost = T.scalar('cost')\n",
    "err = T.vector(name='err')\n",
    "gradient = T.vector(name='gradient')\n",
    "\n",
    "#cost is essentially a multidimensional unit variance, Gaussian centered at m = [1, 2, 3].\n",
    "#The only difference is that the multiplicative normalizing constant is left out.\n",
    "#That doesn't change the location of the maximum which is still at \"m\"\n",
    "err = x - np.array([1.0, 2.0, 3.0])\n",
    "cost =  T.exp((- 0.5) * T.sum((err**2)))\n",
    "\n",
    "#gradient of the cost wrt the vector x\n",
    "gradient = T.grad(cost, wrt=x)\n",
    "\n",
    "#update step\n",
    "update = [[x, x + 1.0 * gradient]]\n",
    "\n",
    "train = function([], outputs = cost, updates=update)\n",
    "#train = function([], outputs = cost, updates=update, mode='DebugMode')\n",
    "nSteps = 100\n",
    "\n",
    "for i in range(nSteps):\n",
    "    train()\n",
    "    if i % 10 == 0: print i, x.get_value(), cost.eval()\n",
    "\n",
    "theano.printing.pprint(cost)\n",
    "#theano.printing.debugprint(cost) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Q's\n",
    "1.  Walk through the code one line at a time and describe what the line is doing. \n",
    "2.  Uncomment the first print statement at the bottom of code snip.  Rerun and give a description of added output. \n",
    "3.  Remove the name='x' from the constructor for the shared variable x and describe how that changes the output.  \n",
    "4.  Uncomment the debug print statement (last line) and explain the resulting output.\n",
    "5.  Switch to the debug version of the train function and see if you can introduce a coding error that requires the debug output to unravel. \n",
    "\n",
    "#In-class coding exercise\n",
    "1.  Modify the code above to use momentum method.  The code box below will help you get started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.00136782  0.00273565  0.00410347] 0.000929500163129\n",
      "10 [ 0.016551    0.033102    0.04965299] 0.0011474610305\n",
      "20 [ 0.03534802  0.07069605  0.10604407] 0.0014827244323\n",
      "30 [ 0.05983992  0.11967984  0.17951976] 0.00205535472918\n",
      "40 [ 0.09451585  0.18903169  0.28354754] 0.00321698448097\n",
      "50 [ 0.15207815  0.3041563   0.45623445] 0.00652052581711\n",
      "60 [ 0.30087555  0.6017511   0.90262665] 0.0326658541905\n",
      "70 [ 0.99633654  1.99267309  2.98900963] 0.999906058086\n",
      "80 [ 0.99999642  1.99999285  2.99998927] 0.99999999991\n",
      "90 [ 1.          1.99999999  2.99999999] 1.0\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'mike.bowles'\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano import function\n",
    "import numpy as np\n",
    "\n",
    "x = theano.shared(np.array([0.0,0.0,0.0]),name='x')\n",
    "cost = T.scalar('cost')\n",
    "err = T.vector('err')\n",
    "gradient = T.vector('vector')\n",
    "beta = theano.shared(x.x, name='beta')  #<================ Fill in value here\n",
    "delta = theano.shared(x.x, name='delta')  #<=============== Fill in value here\n",
    "xStep = theano.shared(np.array([0.0,0.0,0.0]),name='xStep')\n",
    "\n",
    "#cost is essentially a multidimensional unit variance, Gaussian centered at m = [1, 2, 3].\n",
    "#The only difference is that the multiplicative normalizing constant is left out.\n",
    "#That doesn't change the location of the maximum which is still at \"m\"\n",
    "err = x - np.array([1.0, 2.0, 3.0])\n",
    "cost =  T.exp((- 0.5) * T.sum((err**2)))\n",
    "\n",
    "#gradient of the cost wrt the vector x\n",
    "gradient = T.grad(cost, wrt=x)\n",
    "xStep =    #<========================== Fill in code here (hint: look at lecture notes on momentum)\n",
    "\n",
    "#update step\n",
    "update = [[x, x + xStep]]\n",
    "\n",
    "train = function([], outputs = cost, updates=update)\n",
    "#train = function([], outputs = cost, updates=update, mode='DebugMode')\n",
    "nSteps = 100\n",
    "\n",
    "for i in range(nSteps):\n",
    "    train()\n",
    "    if i % 10 == 0: print i, x.get_value(), cost.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Q's\n",
    "1.  It's a pain to adjust the parameters beta and delta by altering the code, recompiling and rerunning.  Since those get changed frequently, it would be better to make them inputs to the function train().  Outline the steps required to do that. \n",
    "\n",
    "##In-class Coding exercise\n",
    "1.  Below is code that treats beta and delta as inputs and that makes the center of the Gaussian-like function an input as well.  It has a bug in it.  See if you can find it.  See if the graph printing statements help you find it quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.00136782  0.00273565  0.00410347]"
     ]
    },
    {
     "ename": "MissingInputError",
     "evalue": "(\"An input of the graph, used to compute Elemwise{sub,no_inplace}(x, m), was not provided and not given a value.Use the Theano flag exception_verbosity='high',for more information on this error.\", m)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingInputError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-cff1ef0d0f11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnSteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ubuntu/Applications/anaconda/lib/python2.7/site-packages/theano/gof/graph.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, inputs_to_values)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/Applications/anaconda/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                 profile=profile)\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/Applications/anaconda/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    509\u001b[0m     return orig_function(inputs, cloned_outputs, mode,\n\u001b[0;32m    510\u001b[0m             \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             on_unused_input=on_unused_input)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/Applications/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input)\u001b[0m\n\u001b[0;32m   1463\u001b[0m                    \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1465\u001b[1;33m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1466\u001b[0m                        defaults)\n\u001b[0;32m   1467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/Applications/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph)\u001b[0m\n\u001b[0;32m   1131\u001b[0m             \u001b[0mneed_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m             \u001b[1;31m# make the fgraph (copies the graph, creates NEW INPUT AND OUTPUT VARIABLES)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m             \u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madditional_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd_fgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_inplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m             \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/Applications/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36mstd_fgraph\u001b[1;34m(input_specs, output_specs, accept_inplace)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0morig_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_specs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[0mfgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunctionGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/Applications/anaconda/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, features, clone)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__import_r__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"init\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/Applications/anaconda/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__import_r__\u001b[1;34m(self, variables, reason)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mapply_node\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvariables\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mapply_node\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapply_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/Applications/anaconda/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__import__\u001b[1;34m(self, apply_node, check, reason)\u001b[0m\n\u001b[0;32m    360\u001b[0m                             \u001b[1;34m\"for more information on this error.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m                             % str(node)),\n\u001b[1;32m--> 362\u001b[1;33m                             r)\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMissingInputError\u001b[0m: (\"An input of the graph, used to compute Elemwise{sub,no_inplace}(x, m), was not provided and not given a value.Use the Theano flag exception_verbosity='high',for more information on this error.\", m)"
     ]
    }
   ],
   "source": [
    "__author__ = 'mike.bowles'\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano import function\n",
    "import numpy as np\n",
    "\n",
    "x = theano.shared(np.array([0.0,0.0,0.0]),name='x')\n",
    "cost = T.scalar('cost')\n",
    "err = T.vector('err')\n",
    "gradient = T.vector('vector')\n",
    "beta = T.scalar(name='beta')\n",
    "delta = T.scalar(name='delta')\n",
    "xStep = theano.shared(np.array([0.0,0.0,0.0]),name='xStep')\n",
    "m = T.vector(name='m')\n",
    "\n",
    "#cost is essentially a multidimensional unit variance, Gaussian centered at m = [1, 2, 3].\n",
    "#The only difference is that the multiplicative normalizing constant is left out.\n",
    "#That doesn't change the location of the maximum which is still at \"m\"\n",
    "err = x - m\n",
    "cost =  T.exp((- 0.5) * T.sum((err**2)))\n",
    "\n",
    "#gradient of the cost wrt the vector x\n",
    "gradient = T.grad(cost, wrt=x)\n",
    "xStep = beta * xStep + (1 - beta) * delta * gradient\n",
    "\n",
    "#update step\n",
    "update = [[x, x + xStep]]\n",
    "\n",
    "train = function([beta, delta, m], outputs = cost, updates=update)\n",
    "#train = function([], outputs = cost, updates=update, mode='DebugMode')\n",
    "nSteps = 100\n",
    "\n",
    "for i in range(nSteps):\n",
    "    train(0.7, 5.0, np.array([1.0, 2.0, 3.0]))\n",
    "    if i % 10 == 0: print i, x.get_value()#, cost.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Building a neural net with Theano\n",
    "Now return to the simple neural net that you trained last week.  You have all the Theano tools to train that neural net using Theano.  The code for that is in the code box below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-9.99842204  9.99747987]\n",
      "50 [-9.91386469  9.87526903]\n",
      "100 [-9.82122285  9.75772079]\n",
      "150 [-9.72342534  9.64210187]\n",
      "200 [-9.62209163  9.52686775]\n",
      "250 [-9.51810666  9.4111443 ]\n",
      "300 [-9.4119438   9.29443483]\n",
      "350 [-9.30384656  9.17645495]\n",
      "400 [-9.19393077  9.05703986]\n",
      "450 [-9.08224203  8.93609249]\n",
      "500 [-8.96878786  8.81355495]\n",
      "550 [-8.85355588  8.6893929 ]\n",
      "600 [-8.73652406  8.56358734]\n",
      "650 [-8.61766675  8.4361304 ]\n",
      "700 [-8.49695832  8.3070236 ]\n",
      "750 [-8.37437572  8.17627727]\n",
      "800 [-8.2499003   8.04391084]\n",
      "850 [-8.12351956  7.90995349]\n",
      "900 [-7.9952288   7.77444519]\n",
      "950 [-7.86503282  7.63743784]\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'mike.bowles'\n",
    "import random\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano import pp\n",
    "import numpy as np\n",
    "\n",
    "numRows = 200\n",
    "noiseSd = 0.5\n",
    "X1 = []; X2 = []; Yin = []\n",
    "for i in range(numRows):\n",
    "    #generate attributes x1 and x2 by drawing from uniform (0,1)\n",
    "    x1 = random.random()\n",
    "    x2 = random.random()\n",
    "    y = 0.0\n",
    "    if x2 > (x1 + random.normalvariate(0.0, noiseSd)):\n",
    "        y = 1.0\n",
    "    X1.append(x1); X2.append(x2); Yin.append(y);\n",
    "\n",
    "#Form (nrows x 2) np matrix of x-values\n",
    "Xin = np.array([np.array([x1, x2]) for (x1, x2) in zip(X1, X2)])\n",
    "\n",
    "X = T.matrix(name='X')\n",
    "Y = T.vector(name='Y')\n",
    "cost = T.scalar(name='cost')\n",
    "y = T.vector(name='y')\n",
    "\n",
    "w = theano.shared(np.asarray([-10.0, 10.0]), name='w')\n",
    "y = T.nnet.sigmoid(T.dot(X, w))\n",
    "\n",
    "cost = T.mean(T.sqr(y - Y))\n",
    "gradient = T.grad(cost=cost, wrt=w)\n",
    "updates = [[w, w - gradient * 1.0]]\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "for i in range(1000):\n",
    "    train(Xin, Yin)\n",
    "    if i % 50 == 0: print i, w.get_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q's\n",
    "1.  Go through the code one line at a time and explain what each line is doing.  \n",
    "2.  What is the shape of T.dot(X, w)?  What are the shapes of X and w?  \n",
    "\n",
    "#Homework\n",
    "1.  Modify the code above to use momentum method instead of gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
