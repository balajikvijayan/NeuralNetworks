{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Final Skills Test\n",
    "\n",
    "###Background:\n",
    "Bengio's students wrote a paper discussing the use of neural nets for predicting sunspot activity.  Here's a link to their paper: \n",
    "http://bengio.abracadoudou.com/cv/publications/pdf/fessant_1995_ag.pdf\n",
    "\n",
    "The paper discusses several neural net approaches that they take to the problem.  One they call multi layer perceptron (MLP).  That corresponds to what we have been calling a fully connected feed forward network.  They also train an Elman net which is the first RNN that we looked at in class.  \n",
    "\n",
    "They are predicting sunspot activity, which is important to communications traffic because it affects the ionospheric conditions in a way that alters the transmission of radio waves on earth.  Reflection of some radio waves off of the ionosphere makes it possible to communicate over the horizon and sunspot activity can alter the frequencies that the ionosphere reflects.  (Notice that one of the students was at CNET - France Telecom's lab for communications studies.)\n",
    "\n",
    "You can see from the plot in the paper (or by plotting the attached files) that sunspots are roughly periodic with a period around 11 years.  The task here is to build your own neural nets to accomplish this prediction and to compare your results to the results that Bengio and his students got in their paper.  \n",
    "\n",
    "You'll see in the paper some discussion of \"embedding dimension\".  Consider how you'd use a fully connected feed forward network to do time series prediction.  The usual method is to give the FC a segment of the time series that includes the present value and several values into the past and then train the FC network against labels that are the future value.  The width of the input layer (the number of past values given the network) is called the \"embedding dimension\".  \n",
    "\n",
    "The authors also used an Elman Net for the prediction task and as you know from your own experimentation with RNN, you can train an RNN the current time series point alone or on the current and past values - so it's relevant to think about optimum embedding dimension for RNN as well as for FC network.  \n",
    "\n",
    "###Problem Statement:  \n",
    "Build two networks to predict sunspot activity 6 months ahead.  One should be a fully connected feed forward network and the other should be an LSTM.  For each try a few different embedding dimensions.  Compare your best performing FC and your best performing LSTM with the results that the authors got in their paper.  \n",
    "\n",
    "There are two data sets included in this folder.  Both come from the Royal Solar Observatory in Belgium.  One is daily sunspot data dating from the early 19th century.  The other is monthly data dating from the late 18th century.  You may use either data set (or both).  You'll get the most direct comparison using the monthly data.  Submit python notebook with working code (including output) and the writeup of your comparison.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
