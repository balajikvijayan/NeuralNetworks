{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Lecture 4.2 - LeNet, Convolutional Neural Net (CNN)\n",
    "\n",
    "##Learning Objectives\n",
    "1.  What is a convolutional layer is, why is it used and on what types of problems.\n",
    "2.  What are typical convolutional neural net (CNN) architectures\n",
    "3.  How are convolutional layers sized\n",
    "4.  What choices need to be made in designing a CNN?\n",
    "\n",
    "##Topics for today\n",
    "1.  Intro CNN\n",
    "2.  Basic elements of CNN and their function\n",
    "3.  Layer sizing calculations\n",
    "4.  Tradeoffs between convolutional receptive field and network depth\n",
    "5.  Architectural choices and trends\n",
    "\n",
    "\n",
    "##Pre-reading materials\n",
    "\n",
    "http://cs231n.github.io/convolutional-networks/ - Andrej Karpathy - Intro to CNN.  Go over this before class.  Lecture will discuss several sections.\n",
    "\n",
    "http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf - Paper describing 2012 winning imagenet entry\n",
    "\n",
    "\n",
    "##Convolutional Neural Nets\n",
    "\n",
    "You saw in an earlier lecture that convolution transforms an image into a new image by performing a mapping on groups adjacent pixels.  The wikipedia page gives a one-dimensional example https://en.wikipedia.org/wiki/Convolution and you'll see some more examples later in this discussion.  The attraction of using a convolutional operator is that it takes fewer weights and therefore isn't as prone to overfit as a fully connected layer would be.  fewer weights also makes a convolutional layer easier to train.  For its success, a convolutional layer depends on local features being useful across the whole input array.  For example detecting edges is likely to be a useful feature across all of an image.  That's a property of images that may not hold for other types of data.  \n",
    "\n",
    "##Q's\n",
    "1  It is useful to visualize the input to a convolutional layer as a volume with two dimensions representing the two dimensions of the input image.  What is the other dimension of the volume - for the input layer, for subsequent layers?\n",
    "\n",
    "2  The MNIST data set contains 28x28 pixel images.  How many weights would be required for a fully neuron in the first hidden layer that's fully connected to the input layer?  How many would be required for 3x3 convolution?  Roughly how many features would the 3x3 convolution generate?\n",
    "\n",
    "\n",
    "##In-class exercises\n",
    "\n",
    "1 The two code blocks immediately below provide a setup for you to experiment with the theano nnet.conv.conv2d function and the signal.downsample.max_pool_2d function.  Run a couple of test examples through each one of these and confirm that the input and output dimensions satisfy the formula in Karpathy's writeup and the formula in the theano documentation for the function.  \n",
    "\n",
    "2  The third code block sets up a CNN for MNIST.  On a layer-by-layer basis the shape of the layer outputs are:\n",
    "(128, 32, 15, 15) (128, 64, 7, 7) (128, 1152) (128, 625).  At the end of the code for the MNIST CNN, you can see the print statement (commented) that generated these shape tuples for each of the layer outputs.  Run through the calculations to confirm these dimensions starting from the layer input, the settings in the conv2d and max_pool functions and the dimensions used to initialize the layer-by-layer weights.  Use both the calculations and the code snips to confirm that you get the same result.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(128, 32, 15, 15) (128, 64, 7, 7) (128, 1152) (128, 625) - printed from CNN code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  29.   30.   31.   32.   33.   34.   35.   36.   37.   38.   39.   40.\n",
      "      41.   42.   43.   44.   45.   46.   47.   48.   49.   50.   51.   52.\n",
      "      53.   54.]\n",
      "   [  57.   58.   59.   60.   61.   62.   63.   64.   65.   66.   67.   68.\n",
      "      69.   70.   71.   72.   73.   74.   75.   76.   77.   78.   79.   80.\n",
      "      81.   82.]\n",
      "   [  85.   86.   87.   88.   89.   90.   91.   92.   93.   94.   95.   96.\n",
      "      97.   98.   99.  100.  101.  102.  103.  104.  105.  106.  107.  108.\n",
      "     109.  110.]\n",
      "   [ 113.  114.  115.  116.  117.  118.  119.  120.  121.  122.  123.  124.\n",
      "     125.  126.  127.  128.  129.  130.  131.  132.  133.  134.  135.  136.\n",
      "     137.  138.]\n",
      "   [ 141.  142.  143.  144.  145.  146.  147.  148.  149.  150.  151.  152.\n",
      "     153.  154.  155.  156.  157.  158.  159.  160.  161.  162.  163.  164.\n",
      "     165.  166.]\n",
      "   [ 169.  170.  171.  172.  173.  174.  175.  176.  177.  178.  179.  180.\n",
      "     181.  182.  183.  184.  185.  186.  187.  188.  189.  190.  191.  192.\n",
      "     193.  194.]\n",
      "   [ 197.  198.  199.  200.  201.  202.  203.  204.  205.  206.  207.  208.\n",
      "     209.  210.  211.  212.  213.  214.  215.  216.  217.  218.  219.  220.\n",
      "     221.  222.]\n",
      "   [ 225.  226.  227.  228.  229.  230.  231.  232.  233.  234.  235.  236.\n",
      "     237.  238.  239.  240.  241.  242.  243.  244.  245.  246.  247.  248.\n",
      "     249.  250.]\n",
      "   [ 253.  254.  255.  256.  257.  258.  259.  260.  261.  262.  263.  264.\n",
      "     265.  266.  267.  268.  269.  270.  271.  272.  273.  274.  275.  276.\n",
      "     277.  278.]\n",
      "   [ 281.  282.  283.  284.  285.  286.  287.  288.  289.  290.  291.  292.\n",
      "     293.  294.  295.  296.  297.  298.  299.  300.  301.  302.  303.  304.\n",
      "     305.  306.]\n",
      "   [ 309.  310.  311.  312.  313.  314.  315.  316.  317.  318.  319.  320.\n",
      "     321.  322.  323.  324.  325.  326.  327.  328.  329.  330.  331.  332.\n",
      "     333.  334.]\n",
      "   [ 337.  338.  339.  340.  341.  342.  343.  344.  345.  346.  347.  348.\n",
      "     349.  350.  351.  352.  353.  354.  355.  356.  357.  358.  359.  360.\n",
      "     361.  362.]\n",
      "   [ 365.  366.  367.  368.  369.  370.  371.  372.  373.  374.  375.  376.\n",
      "     377.  378.  379.  380.  381.  382.  383.  384.  385.  386.  387.  388.\n",
      "     389.  390.]\n",
      "   [ 393.  394.  395.  396.  397.  398.  399.  400.  401.  402.  403.  404.\n",
      "     405.  406.  407.  408.  409.  410.  411.  412.  413.  414.  415.  416.\n",
      "     417.  418.]\n",
      "   [ 421.  422.  423.  424.  425.  426.  427.  428.  429.  430.  431.  432.\n",
      "     433.  434.  435.  436.  437.  438.  439.  440.  441.  442.  443.  444.\n",
      "     445.  446.]\n",
      "   [ 449.  450.  451.  452.  453.  454.  455.  456.  457.  458.  459.  460.\n",
      "     461.  462.  463.  464.  465.  466.  467.  468.  469.  470.  471.  472.\n",
      "     473.  474.]\n",
      "   [ 477.  478.  479.  480.  481.  482.  483.  484.  485.  486.  487.  488.\n",
      "     489.  490.  491.  492.  493.  494.  495.  496.  497.  498.  499.  500.\n",
      "     501.  502.]\n",
      "   [ 505.  506.  507.  508.  509.  510.  511.  512.  513.  514.  515.  516.\n",
      "     517.  518.  519.  520.  521.  522.  523.  524.  525.  526.  527.  528.\n",
      "     529.  530.]\n",
      "   [ 533.  534.  535.  536.  537.  538.  539.  540.  541.  542.  543.  544.\n",
      "     545.  546.  547.  548.  549.  550.  551.  552.  553.  554.  555.  556.\n",
      "     557.  558.]\n",
      "   [ 561.  562.  563.  564.  565.  566.  567.  568.  569.  570.  571.  572.\n",
      "     573.  574.  575.  576.  577.  578.  579.  580.  581.  582.  583.  584.\n",
      "     585.  586.]\n",
      "   [ 589.  590.  591.  592.  593.  594.  595.  596.  597.  598.  599.  600.\n",
      "     601.  602.  603.  604.  605.  606.  607.  608.  609.  610.  611.  612.\n",
      "     613.  614.]\n",
      "   [ 617.  618.  619.  620.  621.  622.  623.  624.  625.  626.  627.  628.\n",
      "     629.  630.  631.  632.  633.  634.  635.  636.  637.  638.  639.  640.\n",
      "     641.  642.]\n",
      "   [ 645.  646.  647.  648.  649.  650.  651.  652.  653.  654.  655.  656.\n",
      "     657.  658.  659.  660.  661.  662.  663.  664.  665.  666.  667.  668.\n",
      "     669.  670.]\n",
      "   [ 673.  674.  675.  676.  677.  678.  679.  680.  681.  682.  683.  684.\n",
      "     685.  686.  687.  688.  689.  690.  691.  692.  693.  694.  695.  696.\n",
      "     697.  698.]\n",
      "   [ 701.  702.  703.  704.  705.  706.  707.  708.  709.  710.  711.  712.\n",
      "     713.  714.  715.  716.  717.  718.  719.  720.  721.  722.  723.  724.\n",
      "     725.  726.]\n",
      "   [ 729.  730.  731.  732.  733.  734.  735.  736.  737.  738.  739.  740.\n",
      "     741.  742.  743.  744.  745.  746.  747.  748.  749.  750.  751.  752.\n",
      "     753.  754.]]]]\n",
      "(1, 1, 26, 26)\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'mike.bowles'\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import numpy as np\n",
    "from theano.tensor.signal.downsample import max_pool_2d\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "\n",
    "X = theano.shared(np.array(range(784), dtype=theano.config.floatX).reshape((1,1,28,28)))\n",
    "w = theano.shared(np.array([[[[0.0, 0.0, 0.0],\n",
    "                  [0.0, 1.0, 0.0],\n",
    "                  [0.0, 0.0, 0.0]]]], dtype=theano.config.floatX))\n",
    "convOut = conv2d(X, w, border_mode='valid')  #border_mode={'valid', 'full'}\n",
    "\n",
    "\n",
    "convOutTest = convOut.eval()\n",
    "print convOutTest\n",
    "print convOutTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape     (3, 3)\n"
     ]
    }
   ],
   "source": [
    "imageTmp = T.matrix(\"imageTemp\")\n",
    "testOut = T.signal.downsample.max_pool_2d(imageTmp,\n",
    "                                          ds=(2,2),\n",
    "                                          ignore_border=False,\n",
    "                                          st=None,\n",
    "                                          padding=(0,0)) \n",
    "\n",
    "poolTest = theano.function([imageTmp], testOut)\n",
    "\n",
    "shape = (5, 5)\n",
    "testIn = np.ones(shape, dtype=theano.config.floatX)\n",
    "\n",
    "\n",
    "print 'function method   ', poolTest(testIn)\n",
    "print 'shape    ', poolTest(testIn).shape\n",
    "print 'eval method    ', testOut.eval({imageTmp: testIn})\n",
    "\n",
    "testIn2 = np.array([[1.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0],\n",
    "                    [2.0, 3.0, 4.0, 5.0, 4.0, 3.0, 2.0],\n",
    "                    [3.0, 4.0, 5.0, 6.0, 5.0, 4.0, 3.0],\n",
    "                    [2.0, 3.0, 4.0, 5.0, 4.0, 3.0, 2.0],\n",
    "                    [1.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0]], dtype=theano.config.floatX)\n",
    "print 'location of max  ', poolTest(testIn)\n",
    "\n",
    "print testOut.eval({imageTmp: testIn2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q's\n",
    "1  Use sample code above to verify calculations of input-output sizing and weight dimensions in code below.  \n",
    "2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.downsample import max_pool_2d\n",
    "\n",
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.)\n",
    "    #return T.maximum(X, 0.01*X)  #leaky rectifier\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def dropout(X, p=0.0):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "def model(X, w, w2, w3, w4, p_drop_conv, p_drop_hidden):\n",
    "    l1a = rectify(conv2d(X, w, border_mode='full'))\n",
    "    l1 = max_pool_2d(l1a, (2, 2))\n",
    "    l1 = dropout(l1, p_drop_conv)\n",
    "\n",
    "    l2a = rectify(conv2d(l1, w2))\n",
    "    l2 = max_pool_2d(l2a, (2, 2))\n",
    "    l2 = dropout(l2, p_drop_conv)\n",
    "\n",
    "    l3a = rectify(conv2d(l2, w3))\n",
    "    l3b = max_pool_2d(l3a, (2, 2))\n",
    "    l3 = T.flatten(l3b, outdim=2)\n",
    "    l3 = dropout(l3, p_drop_conv)\n",
    "\n",
    "    l4 = rectify(T.dot(l3, w4))\n",
    "    l4 = dropout(l4, p_drop_hidden)\n",
    "\n",
    "    pyx = softmax(T.dot(l4, w_o))\n",
    "    return l1, l2, l3, l4, pyx\n",
    "\n",
    "\n",
    "\n",
    "xTrain = xTrain.reshape(-1, 1, 28, 28)\n",
    "xTest = xTest.reshape(-1, 1, 28, 28)\n",
    "\n",
    "X = T.ftensor4()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "w = init_weights((32, 1, 3, 3))\n",
    "w2 = init_weights((64, 32, 3, 3))\n",
    "w3 = init_weights((128, 64, 3, 3))\n",
    "w4 = init_weights((128 * 3 * 3, 625))\n",
    "w_o = init_weights((625, 10))\n",
    "\n",
    "noise_l1, noise_l2, noise_l3, noise_l4, noise_py_x = model(X, w, w2, w3, w4, 0.2, 0.5)\n",
    "l1, l2, l3, l4, py_x = model(X, w, w2, w3, w4, 0., 0.)\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "\n",
    "\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "params = [w, w2, w3, w4, w_o]\n",
    "updates = RMSprop(cost, params, lr=0.001)\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "\n",
    "for i in range(100):\n",
    "    for start, end in zip(range(0, len(xTrain), 128), range(128, len(xTrain), 128)):\n",
    "        cost = train(xTrain[start:end], yTrain[start:end])\n",
    "        #a, b, c, d, e = model(floatX(trX[start:end]), w, w2, w3, w4, 0., 0.)\n",
    "        #print a.eval().shape, b.eval().shape, c.eval().shape, d.eval().shape\n",
    "    print np.mean(np.argmax(yTest, axis=1) == predict(xTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results - These results were generated in an off-line run.  They represent 20 passes through the MNIST data and took approximately 18 hours of computing time on single CPU.\n",
    "\n",
    "0.9332 0.9744 0.9834 0.9828 0.9891 0.9869 0.9911 0.9914 0.992 0.9928 0.9935 0.9923 0.9937 0.9931 0.9934 0.9938 0.9942 0.9938 0.9935 0.9945 0.9934 0.9937 0.9944 0.9938\n",
    "\n",
    "##Homework\n",
    "1  Karpathy's notes on convolutional networks suggest that performance can be improved by removimg some the max pooling layers - particularly the ones early in the network.  Test this suggestion by removing the first  pooling layer from the network above and rearrange the sizing on convolutional layers to adjust for this removal.  Run the network to demonstrate that your rearrangement works and to get a feel for the resulting improvement or deterioration of performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
