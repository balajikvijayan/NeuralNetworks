{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Lecture 4.1 - Training a Neural Net\n",
    "\n",
    "\n",
    "##Pre-reading\n",
    "\n",
    "The following two references are related.  The first is the full text of a paper.  The second is an outline of the topics covered.  You might skim the first one and the look at the outline to see what you missed or to uncover things you'd like to look at in more detail.\n",
    "\n",
    "http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf - full text of paper on problems and approaches to training\n",
    "\n",
    "https://aresearch.wordpress.com/2015/04/11/efficient-backprop-lecun-bottou-orr-muller-neural-networks-tricks-of-the-trade-1998q/ - outline summary of paper above \n",
    "\n",
    "http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40808.pdf -  empirical learning rate algo - google ny\n",
    "\n",
    "http://arxiv.org/pdf/1206.1106.pdf - Shaul (w. LeCun) paper on adaptive learning\n",
    "\n",
    "http://arxiv.org/pdf/1301.3764.pdf - Shaul replaces diagonal Hessian w finite difference approx\n",
    "\n",
    "\n",
    "##Learning Goals\n",
    "\n",
    "\n",
    "##Training problems\n",
    "\n",
    "As you've discovered from the last homework problem, neural nets are a pain to train.  The difficulties with training neural nets have been a source of criticism for neural nets.  For example look at the strong language used in the training section of the wikipedia page on neural nets.  https://en.wikipedia.org/wiki/Artificial_neural_network#Training_issues\n",
    "\n",
    "The quote on wikipedia comes from 1997, the dark ages for neural nets.  Things have improved, but as you saw with the home work, they can still be tough to train.  In today's class you'll learn how to monitor the progress of training and what to do if your network isn't training properly.  \n",
    "\n",
    "The code below has several flexibilities built in so you can alter the training properties of the network and see how it affects the training performance.  Your goal for the class is to learn how to determine what's going wrong in the network you're training and to the modify the network in a manner that fixes the problem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from cifarHandler import cifar\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    (h, w) = shape\n",
    "    # Glorot normalization - last factor depends on non-linearity\n",
    "    # 0.25 for sigmoid and 0.1 for softmax, 1.0 for tanh or Relu\n",
    "    normalizer = 2.0 * sqrt(6) / sqrt(h + w) * 1.0\n",
    "    #return theano.shared(floatX(np.random.randn(*shape) * 0.01))  #code for standard initialization\n",
    "    #code for using Glorot initialization\n",
    "    return theano.shared(floatX((np.random.random_sample(shape) - 0.5) * normalizer))\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.)\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "def adaGrad(cost, params, eta=0.1, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        sumGSq = theano.shared(p.get_value() * 0.)\n",
    "        sumGSq_new = sumGSq + g ** 2\n",
    "        gradient_scaling = T.sqrt(sumGSq_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((sumGSq, sumGSq_new))\n",
    "        updates.append((p, p - eta * g))\n",
    "    return updates\n",
    "\n",
    "def adaDelta(cost, params, eta=1.0, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        #calc g-squared\n",
    "        gSq = theano.shared(p.get_value() * 0.)\n",
    "        dwSq = theano.shared(p.get_value() * 0.)\n",
    "\n",
    "        #exp smoothed g squared\n",
    "        gSqNew = rho * gSq + (1 - rho) * g * g\n",
    "\n",
    "        #calc dx-squared\n",
    "        dw = eta * T.sqrt(dwSq + epsilon) * g / T.sqrt(gSq + epsilon)\n",
    "        dwSqNew = rho * dwSq + (1 - rho) * dw * dw\n",
    "\n",
    "        updates.append((dwSq, dwSqNew))\n",
    "        updates.append((gSq, gSqNew))\n",
    "        updates.append((p, p - dw))\n",
    "    return updates\n",
    "\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "def model(X, w_h, w_h2, w_o, p_drop_input, p_drop_hidden):\n",
    "    X = dropout(X, p_drop_input)\n",
    "    h = rectify(T.dot(X, w_h))\n",
    "\n",
    "    h = dropout(h, p_drop_hidden)\n",
    "    h2 = rectify(T.dot(h, w_h2))\n",
    "\n",
    "    h2 = dropout(h2, p_drop_hidden)\n",
    "    py_x = softmax(T.dot(h2, w_o))\n",
    "    return h, h2, py_x\n",
    "\n",
    "\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "w_h = init_weights((3072, 1500))\n",
    "w_h2 = init_weights((1500, 700))\n",
    "w_o = init_weights((700, 10))\n",
    "\n",
    "noise_h, noise_h2, noise_py_x = model(X, w_h, w_h2, w_o, 0.2, 0.5)\n",
    "h, h2, py_x = model(X, w_h, w_h2, w_o, 0., 0.)\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "params = [w_h, w_h2, w_o]\n",
    "\n",
    "#updates = RMSprop(cost, params, lr=0.0001)\n",
    "#updates = adaGrad(cost, params, eta=0.001, epsilon=0.01) #\n",
    "updates = adaDelta(cost, params, eta=0.1, rho=0.9, epsilon=0.1)\n",
    "\n",
    "xTrain, yTrain, xTest, yTest = cifar(2, True)\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "\n",
    "\n",
    "for i in range(101):\n",
    "    iJump = 128\n",
    "\n",
    "    for start, end in zip(range(0, len(xTrain), iJump), range(iJump, len(xTrain), iJump)):\n",
    "        cost = train(xTrain[start:end], yTrain[start:end])\n",
    "        print i, np.mean(np.argmax(yTest, axis=1) == predict(xTest)), np.mean(w_h.get_value()), np.mean(w_h2.get_value())\n",
    "\n",
    "    #asList = list(itertools.chain.from_iterable((w_h.get_value()).tolist()))\n",
    "    #plt.hist(asList)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##In-class training exercises\n",
    "1  Use only one of the cifar training data sets.  Use RMSprop updates for the weights. Set normalization to \"False\" in the routine that reads in Cifar data.  Increase the learning rate until the network obviously overtrains.  What characterizes over-training behavior?  How can you identify it?  When the network is overtraining, uncomment the plot-related statements at the bottom of the code and observe what the corresponding histogram looks like as the network overtrains.\n",
    "\n",
    "2  Comment on any odd behaviors that you observe in the weight matrix as it's training.  \n",
    "\n",
    "\n",
    "3  Try this exercise with the other choices for update that are available in the code for this network.  Does one of the update algorithms seem more or less well behaved to you?  What properties make it stand out?\n",
    "\n",
    "4  Pick the worst behaved algorithm (in your view) and change the \"Normalized\" option for the cifar reader to \"True\".  Do the same thing with the best behaved algorithm.  How much difference would you say normalization makes.  Can you get both the best and the worst update algorithms to train?  \n",
    "\n",
    "5  Change the number of data packages included in the training to 5, so that the all the data are available for training.  Start training with the parameter settings that you got working in the last exercise.  Monitor the training by looking at the available output variables.  Add your own if you like.  Does adding more data make it so you can increase the learning parameter and train more rapidly?  \n",
    "\n",
    "##Homework\n",
    "Build a function to perform Nesterov updates and run enough training to compare it to your favorite. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
